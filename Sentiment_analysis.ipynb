{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d6c1c-617e-46a6-8f25-965cbf10f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text preprocessing...\n",
      "Text preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, names=['review', 'sentiment'], header=None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    words = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def apply_preprocessing(df):\n",
    "    print(\"Starting text preprocessing...\")\n",
    "    df['clean_review'] = df['review'].apply(preprocess_text)\n",
    "    print(\"Text preprocessing complete.\")\n",
    "    return df\n",
    "\n",
    "def feature_extraction(df):\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X = vectorizer.fit_transform(df['clean_review'])\n",
    "    return X, vectorizer\n",
    "\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    models = {}\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    models['Naive Bayes'] = nb\n",
    "    \n",
    "    svm = SVC(kernel='linear', probability=True)\n",
    "    svm.fit(X_train, y_train)\n",
    "    models['SVM'] = svm\n",
    "    return models\n",
    "\n",
    "def cross_validate_models(models, X_train, y_train):\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"{name} acc: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nEvaluating model: {name}\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, pos_label='positive')\n",
    "        recall = recall_score(y_test, y_pred, pos_label='positive')\n",
    "        f1 = f1_score(y_test, y_pred, pos_label='positive')\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "        plt.title(f'{name} Confusion Matrix')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.show()\n",
    "\n",
    "def visualize_wordcloud(df, sentiment):\n",
    "    text = ' '.join(df[df['sentiment'] == sentiment]['clean_review'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{sentiment.capitalize()} Review Word Cloud')\n",
    "    plt.show()\n",
    "\n",
    "def save_models(models, vectorizer, model_path='models/'):\n",
    "    import os\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    for name, model in models.items():\n",
    "        joblib.dump(model, os.path.join(model_path, f\"{name}.joblib\"))\n",
    "        print(f\"Saved model: {name}\")\n",
    "    joblib.dump(vectorizer, os.path.join(model_path, \"vectorizer.joblib\"))\n",
    "    print(\"Saved vectorizer.\")\n",
    "\n",
    "def load_models(model_path='models/'):\n",
    "    models = {}\n",
    "    model_files = ['Naive Bayes.joblib', 'SVM.joblib']\n",
    "    for file in model_files:\n",
    "        name = file.replace('.joblib', '')\n",
    "        models[name] = joblib.load(os.path.join(model_path, file))\n",
    "    vectorizer = joblib.load(os.path.join(model_path, \"vectorizer.joblib\"))\n",
    "    print(\"Loaded all models and vectorizer.\")\n",
    "    return models, vectorizer\n",
    "\n",
    "def predict_new_review(review, models, vectorizer):\n",
    "    clean = preprocess_text(review)\n",
    "    X_new = vectorizer.transform([clean])\n",
    "    predictions = {}\n",
    "    for name, model in models.items():\n",
    "        pred = model.predict(X_new)[0]\n",
    "        predictions[name] = pred\n",
    "    return predictions\n",
    "\n",
    "def main():\n",
    "    filepath = 'IMDB_Dataset.csv'\n",
    "    \n",
    "    df = load_data(filepath)\n",
    "     \n",
    "    df = apply_preprocessing(df)\n",
    "    \n",
    "    X, vectorizer = feature_extraction(df)\n",
    "    y = df['sentiment']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    models = train_models(X_train, y_train)\n",
    "\n",
    "    cross_validate_models(models, X_train, y_train)\n",
    "\n",
    "    evaluate_models(models, X_test, y_test)\n",
    "    \n",
    "    visualize_wordcloud(df, 'positive')\n",
    "    visualize_wordcloud(df, 'negative')\n",
    "    \n",
    "    save_models(models, vectorizer)\n",
    "    \n",
    "    sample_review = \" \"\n",
    "    predictions = predict_new_review(sample_review, models, vectorizer)\n",
    "    for model, pred in predictions.items():\n",
    "        print(f\"{model}: {pred}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6e6f0-adb0-42c3-a109-71ef5669a2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
